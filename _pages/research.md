---
layout: page
title: research
permalink: /research/
description: My research interests include <i>machine intelligence</i> and <i>evolutionary computation</i>. Currently, I focus on machine learning, multi-objective optimisation, and their applications in real-world systems.
nav: true
nav_order: 2
display_categories: [research]
horizontal: false
---

<strong>machine learning</strong>

<p align="justify">
Machine learning is the science of getting computers to act without being explicitly programmed. For a learning system, the experience is the process of analysing the collected data (and providing predictions to interact with the environment). From this perspective, machine learning is learning from the data. Prof. Tom M. Mitchell provided a widely quoted definition of learning in the book of Machine Learning, McGraw Hill, 1997.
</p>
<i>Definition: A computer program is said to learn from experience $$\mathcal{E}$$ with respect to some class of tasks $$\mathcal{T}$$and performance measure $$\mathcal{P}$$, if its performance at tasks in $$\mathcal{T}$$, as measured by $$\mathcal{P}$$, improves with experience $$\mathcal{E}$$.</i>

Our work in machine learning includes safe & robust learning, multimodal learning, and manifold learning.

<i>Safe and robust machine learning</i>
<ul>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/ICCV2023_GGI.pdf">ICCV23</a>] A gradient inversion attack method in federated learning</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/MedIA2022_CDACM.pdf">MedIA23</a>] A domain adaptation method for medical image analysis</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/MedIA2022_AMFAM.pdf">MedIA22</a>] An adversarial multimodal learning method for automated skin lesion classification</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/ICLR2022_efficient_sharpness_aware_mini.pdf">ICLR22</a>] A robust optimisation method for deep neural networks</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/TBD22_AMPC.pdf">TBD22</a>] A secure multi-party learning method for federated learning</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/CVPR2021_Learning_Cross-Modal_Retrieval_With_Noisy_Labels_CVPR_2021_paper.pdf">CVPR21</a>] A robust learning method for handling noisy labels</li>
</ul>



<i>Multimodal machine learning</i>
<ul>
<li>[TIP23] A multi-view learning method with graph priors</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/TPAMI2022_Natural_Language_Video_Localization_A_Revisit_in_Span-Based_Question_Answering_Framework.pdf">TPAMI22</a>] An efficient learning method for natural language video localisation</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/TNNLS2022_DMTL_CMR.pdf">TNNLS22</a>] A multimodal transfer learning method</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/TCYB2020_Joint%20Versus%20Independent%20Multiview%20Hashing%20for%20Cross-View%20Retrieval.pdf">TCYB21</a>] An efficient hashing method for cross-view retrieval</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/SIGIR2021_Video_corpus_moment_retrieval.pdf">SIGIR21</a>] An efficient method for video corpus moment retrieval</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/CVPR2019_Deep_Supervised_Cross_modal_Retrieval.pdf">CVPR19</a>] A deep supervised cross-modal retrieval method</li>
<li>[<a href="https://liangli-zhen.github.io/papers/SIGIR2019_Scalable_Deep_Multimodal_Learning_for_Cross-Modal_Retrieval.pdf">SIGIR19</a>] A scalable deep multimodal learning method for cross-modal retrieval</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/SVHN.pdf">MM19</a>] A separated variational hashing method for cross-modal retrieval</li>
<li>[<a href="https://www.sciencedirect.com/science/article/pii/S0950705118300595">KBS18</a>] A local feature-based method for multi-view analysis</li>
</ul>


<i>Manifold learning and subspace analysis</i>
<ul>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/INS2020_Kernel%20Truncated%20Regression%20Representation%20for%20Robust%20Subspace%20Clustering.pdf">INS20</a>] A kernel-based method for subspace clustering</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/Measurement2020_Underdetermined_mixing_matrix_estimation_by_exploiting_sparsity_of_sources.pdf">Measurement20</a>] A method for estimating the mixing matrix of underdetermined systems</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/TNNLS2017_Underdetermined_blind_source_separation_using_sparse_coding.pdf">TNNLS17</a>] An application of sparse coding technique</li>
<li>[<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8081738">Access17</a>] A method by combining sparsity and independence of source for underdetermined blind source separation</li>
<li>[<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838846/">EL14</a>] A manifold learning method for image clustering</li>
<li>[<a href="http://www.jsoftware.us/vol8/jsw0802-21.pdf">JSW13</a>] A manifold learning method for dimension reduction</li>
</ul>

<sup id="fn1">1. Machine Learning, Tom Mitchell, McGraw Hill, 1997.</sup><br><br>


<strong>multi-objective optimisation</strong>


<p align="justify">Multi-objective optimisation, which addresses optimisation problems involving multiple (conflicting) objective functions to be optimised simultaneously, has attracted increasing interest in the evolutionary computation community. A multi-objective optimisation problem (MOP) can be generally
formulated as follows:</p>

$$
  \begin{aligned}
  \min\limits_{\mathbf{x}} ~~& \mathbf{f}(\mathbf{x}) = (f_1(\mathbf{x}), f_2(\mathbf{x}), ..., f_m(\mathbf{x}) ), \\
  \text{s.t.}  ~~ & \mathbf{x} \in \Omega,\\
  & g_i(\mathbf{x}) \le 0, i = 1,..., p, \\  
  & h_j(\mathbf{x}) = 0, j = 1,..., q,  
  \end{aligned}
$$

where $$\mathbf{x} = (x_1, x_2, \dots, x_d) \in \Omega$$ is the decision vector; $$\mathbf{f} \in \Re^m$$ is the objective vector. The decision vector $$\mathbf{x}$$ is composed of $$d$$ decision variables and the objective vector $$\mathbf{f}$$ consists of $$m$$ objective functions, in which each $$f_i(\mathbf{x})$$ maps $$\mathbf{x}$$ from $$\Omega$$ to a scaler. The conditions on $$g_i(\mathbf{x})$$ and $$h_j(\mathbf{x})$$ are known as the inequality and equality constraints, respectively. If the MOP has more than three objectives, it is called a <em>many-objective optimisation problem</em> (MaOP).

<p align="justify"> Our work in multi-objective optimisation includes test problem construction, multi-objective optimisation visualisation, and the design of efficient multi-objective evolutionary algorithms. </p>

<i>Test problems for multi-objective optimisation</i>
<ul>
<li>[<a href="https://arxiv.org/abs/1806.02706">ArVix22</a>] A benchmark for multiobjective optimisation</li>
</ul>

<i>Visualisation for multi-objective optimisation</i>
<ul>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/INS2020_Objective_reduction_for_visualising_many-objective_solution_sets.pdf">INS20</a>] A visualisation method for multi-objective solution sets using objective reduction</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/CIM2017_How_to_read_many-objective_solution_sets_in_parallel_coordinates.pdf">CIM17</a>] A guide on how to read many-objective solution sets in parallel coordinates</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/APC.pdf">SEAL17</a>] Adjusting parallel coordinates for more explicit observation of many-objective search</li>
</ul>


<i>Multi-objective optimisation in deep learning</i>
<ul>
<li>[TEVC23] A neural architecture search algorithm for automated design of GANs</li>
<li>[<a href="https://liangli-zhen.github.io/assets/pdf/CIM2021-Evolutionary_Multi-Objective_Model_Compression_for_Deep_Neural_Networks.pdf">CIM21</a>] An evolutionary multiobjective model compression method for deep neural networks</li>
</ul><br>
